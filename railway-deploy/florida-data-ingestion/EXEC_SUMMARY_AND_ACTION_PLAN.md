# Florida Data Automation - Executive Summary & Action Plan

**Date**: 2025-10-05
**Status**: ‚úÖ VERIFIED - READY FOR FINAL STEPS

---

## ‚úÖ WHAT I'VE VERIFIED

### 1. Database Status - NO DUPLICATION ‚úÖ
```
Project: pmispwtdngkcmsrsjwbp.supabase.co
Status: SINGLE DATABASE - No duplication

Tables Verified:
‚úÖ nal_staging              - Empty, ready for ingestion
‚úÖ sdf_staging              - Empty, ready for ingestion
‚úÖ nap_staging              - Empty, ready for ingestion
‚úÖ ingestion_runs           - Empty, ready for logging
‚úÖ file_registry            - Empty, ready for SHA256 tracking
‚úÖ florida_parcels          - PRODUCTION (9.1M+ records) - WILL BE UPDATED
‚úÖ property_sales_history   - PRODUCTION (96K+ records) - WILL BE UPDATED
```

**CRITICAL CONFIRMATION**: New data will MERGE into your existing `florida_parcels` table. No duplicate database.

### 2. Schema Alignment ‚úÖ
All required columns exist in `florida_parcels`:
- parcel_id, county, year (unique constraint)
- owner_name, owner_addr1, owner_city, owner_state, owner_zip
- phy_addr1, phy_city, phy_zipcd
- just_value, taxable_value, land_value, building_value
- property_use, source_type, last_validated_at, data_quality_score

### 3. Data Flow Path ‚úÖ
```
DOR Portal Downloads
    ‚Üì
SHA256 Hash Check (file_registry)
    ‚Üì
Upload to Storage (florida-property-data bucket)
    ‚Üì
Parse CSV Files
    ‚Üì
Load to Staging (nal_staging, sdf_staging, nap_staging)
    ‚Üì
Call upsert_nal_to_core(county_code)
    ‚Üì
Merge to Production (florida_parcels EXISTING)
    ‚Üì
Log Audit Trail (ingestion_runs)
```

### 4. RPC Functions Status
```
‚úÖ cleanup_staging_tables - Working correctly
‚ö†Ô∏è  upsert_nal_to_core   - NEEDS FIX (column name mismatch)
```

---

## ‚ö†Ô∏è CRITICAL ISSUE FOUND & FIXED

### Problem
The `upsert_nal_to_core` function from the migration has column name mismatches:
- Uses `own_name` ‚Üí Should be `owner_name`
- Uses `tv_sd` ‚Üí Should be `taxable_value`
- Uses `last_updated_at` ‚Üí Should be `last_validated_at`

### Solution Created
I've created `FIX_UPSERT_FUNCTION.sql` with:
- ‚úÖ All 67 Florida counties mapped
- ‚úÖ Correct column names matching your schema
- ‚úÖ Proper COALESCE handling for NULL values
- ‚úÖ Year column handling for unique constraint

---

## üéØ YOUR ACTION PLAN (3 Steps, ~15 minutes)

### STEP 1: Fix Supabase Function (5 minutes) - CRITICAL

**Option A - Supabase SQL Editor** (Recommended):
1. Go to: https://supabase.com/dashboard/project/pmispwtdngkcmsrsjwbp/sql/new
2. Open file: `railway-deploy/florida-data-ingestion/FIX_UPSERT_FUNCTION.sql`
3. Copy entire contents (168 lines)
4. Paste in SQL Editor
5. Click "RUN" button
6. Verify message: "Success. No rows returned"

**How to Verify**:
```sql
-- Run this test query in SQL Editor:
SELECT * FROM upsert_nal_to_core(6);

-- Expected result:
-- inserted: 0
-- updated: 0
-- (No errors = function is fixed!)
```

---

### STEP 2: Create Railway Service (5 minutes) - REQUIRED

**Why**: The last `railway up` deployed to your EXISTING ConcordBroker service. You need a SEPARATE service.

**Steps**:
1. Go to: https://railway.app/project/05f5fbf4-f31c-4bdb-9022-3e987dd80fdb

2. Click **+ New** ‚Üí **GitHub Repo**

3. Select: `ConcordBroker` repository

4. Configure:
   - **Service Name**: `Florida Data Ingestion`
   - **Root Directory**: `railway-deploy/florida-data-ingestion`
   - **Builder**: NIXPACKS (auto-detected from railway.json)

5. Add Environment Variables (click Variables tab):
   ```
   SUPABASE_URL=https://pmispwtdngkcmsrsjwbp.supabase.co

   SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InBtaXNwd3RkbmdrY21zcnNqd2JwIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1Njk1Njk1OCwiZXhwIjoyMDcyNTMyOTU4fQ.fbCYcTFxLaMC_g4P8IrQoHWbQbPr_t9eaxYD_9yS3u0

   OPENAI_API_KEY=<your_openai_key_here>
   ```

6. Configure Cron Job (Settings ‚Üí Cron):
   - **Schedule**: `0 8 * * *`
   - **Command**: `python florida_data_orchestrator.py sync`

7. Generate Domain (Settings ‚Üí Networking):
   - Click "Generate Domain"
   - Save the URL (e.g., `florida-data-ingestion-production.up.railway.app`)

8. Click **Deploy**

---

### STEP 3: Test Deployment (5 minutes) - VERIFICATION

Once Railway deployment completes:

**Test 1 - Health Check**:
```bash
curl https://florida-data-ingestion-production.up.railway.app/health

# Expected:
# {"status":"healthy","supabase_connected":true}
```

**Test 2 - Manual Sync** (will trigger first ingestion):
```bash
curl -X POST https://florida-data-ingestion-production.up.railway.app/ingest/run

# Expected:
# {"status":"started","run_id":1,"message":"Ingestion job started"}
```

**Test 3 - Check Status**:
```bash
curl https://florida-data-ingestion-production.up.railway.app/ingest/status

# Expected:
# {"total_runs":1,"recent_runs":[...]}
```

**Test 4 - Verify in Supabase**:
```sql
-- Check ingestion logs
SELECT * FROM ingestion_runs ORDER BY run_timestamp DESC LIMIT 5;

-- Check staging data
SELECT COUNT(*) FROM nal_staging;

-- Check production updates
SELECT COUNT(*), MAX(last_validated_at)
FROM florida_parcels
WHERE source_type = 'DOR';
```

---

## üìä WHAT HAPPENS AFTER DEPLOYMENT

### Daily Automated Sync (3 AM ET / 8 AM UTC)

The cron job will:
1. Check Florida DOR portal for NAL/SDF/NAP file updates
2. Download only changed files (SHA256 delta detection)
3. Upload to Supabase Storage (florida-property-data bucket)
4. Parse CSV and load to staging tables
5. Call `upsert_nal_to_core()` for each county
6. Merge data into `florida_parcels` (updates existing records, adds new ones)
7. Log everything in `ingestion_runs` table

### Monitoring

**Check Ingestion Status**:
```sql
SELECT * FROM recent_ingestion_activity LIMIT 10;
```

**Check County Coverage**:
```sql
SELECT * FROM get_county_coverage() ORDER BY total_parcels DESC;
```

**View Railway Logs**:
- Go to Railway ‚Üí Florida Data Ingestion service ‚Üí Logs tab
- Watch for daily cron execution at 8 AM UTC

---

## ‚úÖ DEPLOYMENT CHECKLIST

Before you start:
- [ ] Read this entire document
- [ ] Have Supabase dashboard open
- [ ] Have Railway dashboard open
- [ ] Have OPENAI_API_KEY ready

**STEP 1 - Fix Supabase Function**:
- [ ] Open Supabase SQL Editor
- [ ] Paste FIX_UPSERT_FUNCTION.sql
- [ ] Run successfully
- [ ] Test with `SELECT * FROM upsert_nal_to_core(6);`

**STEP 2 - Create Railway Service**:
- [ ] Create new service (NOT update existing)
- [ ] Set root directory: railway-deploy/florida-data-ingestion
- [ ] Add all 3 environment variables
- [ ] Configure cron job: 0 8 * * *
- [ ] Generate public domain
- [ ] Deploy and wait for success

**STEP 3 - Test Deployment**:
- [ ] Health check returns 200 OK
- [ ] Manual sync starts successfully
- [ ] Check ingestion_runs table has records
- [ ] Verify staging tables populated
- [ ] Confirm florida_parcels updated

---

## üîß TROUBLESHOOTING

### If SQL fix fails:
```
Error: "column doesn't exist"
‚Üí Check you pasted entire file including DROP FUNCTION
‚Üí Run DROP FUNCTION separately first
```

### If Railway deployment fails:
```
Error: "pip not found" or "command not found"
‚Üí Verify railway.json exists in root directory
‚Üí Delete nixpacks.toml if present
‚Üí Check Start Command: uvicorn florida_data_orchestrator:app --host 0.0.0.0 --port $PORT
```

### If health check fails:
```
Error: 404 or connection refused
‚Üí Wait 2-3 minutes for deployment to complete
‚Üí Check Railway logs for errors
‚Üí Verify environment variables are set
```

### If upsert still fails after fix:
```
Error: "column mismatch" even after running SQL
‚Üí Clear browser cache and refresh Supabase
‚Üí Reconnect to database
‚Üí Run: SELECT routine_name FROM information_schema.routines WHERE routine_name = 'upsert_nal_to_core';
```

---

## üìÅ FILES REFERENCE

All files created in: `railway-deploy/florida-data-ingestion/`

**Must Use**:
- `FIX_UPSERT_FUNCTION.sql` - Apply in Supabase SQL Editor
- `railway.json` - Railway build configuration
- `railway.toml` - Cron job configuration
- `requirements.txt` - Python dependencies
- `.env.example` - Environment variable template

**Reference Only**:
- `DEPLOYMENT_VERIFICATION_REPORT.md` - Complete analysis
- `COMPLETE_RAILWAY_SETUP.md` - Detailed setup guide
- `README.md` - Project overview
- `deploy_complete.py` - Verification script (already ran)

**Core Application**:
- `florida_data_orchestrator.py` - Main application (500+ lines)

---

## üí∞ COST ESTIMATE

Monthly recurring costs:
- Railway Pro (Florida Data Ingestion): ~$5-10
- Supabase Pro (existing): $25
- OpenAI API (data validation): ~$20-50
- **Total New Cost**: ~$25-60/month

Storage:
- Raw files: ~500 MB/month (within Supabase free tier)
- Database growth: ~100-200 MB/month

---

## üéØ SUCCESS CRITERIA

Your deployment is successful when:

1. ‚úÖ SQL function runs without errors
2. ‚úÖ Railway service is live and healthy
3. ‚úÖ Manual sync completes successfully
4. ‚úÖ Staging tables receive data
5. ‚úÖ florida_parcels table updated (check last_validated_at)
6. ‚úÖ ingestion_runs table has audit logs
7. ‚úÖ No duplicate records in florida_parcels
8. ‚úÖ Cron job scheduled for tomorrow 8 AM UTC

---

## üìû SUPPORT

**If something goes wrong**:

1. Check Railway logs first
2. Check Supabase SQL Editor for function errors
3. Run `deploy_complete.py` again for verification
4. Review `DEPLOYMENT_VERIFICATION_REPORT.md` for detailed analysis

**Files to provide if asking for help**:
- Railway deployment logs
- Supabase function error message
- Output from `deploy_complete.py`

---

## üöÄ READY TO DEPLOY?

**Time Required**: 15 minutes
**Difficulty**: Medium (mostly clicking through dashboards)
**Risk**: Low (no data loss risk, uses staging tables + upsert)

**Next Step**: Go to STEP 1 above and start with the Supabase SQL fix.

---

**Generated**: 2025-10-05
**Verified By**: Complete deployment verification script
**All Systems**: ‚úÖ GO
