{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConcordBroker Data Flow Monitoring Dashboard\n",
    "\n",
    "This notebook provides comprehensive monitoring and analysis of data flow across all ConcordBroker systems.\n",
    "\n",
    "## Features:\n",
    "- Real-time data validation monitoring\n",
    "- Performance analytics\n",
    "- Data quality assessment\n",
    "- Anomaly detection\n",
    "- Self-healing status tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"üìä Data Flow Monitoring Dashboard Initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Connection Setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('../.env.mcp')\n",
    "\n",
    "# Configuration\n",
    "SUPABASE_URL = os.getenv('SUPABASE_URL')\n",
    "SERVICE_ROLE_KEY = os.getenv('SUPABASE_SERVICE_ROLE_KEY')\n",
    "ORCHESTRATOR_API = 'http://localhost:8001'\n",
    "\n",
    "# Database connection\n",
    "def get_db_connection():\n",
    "    \"\"\"Create database connection\"\"\"\n",
    "    try:\n",
    "        db_url = SUPABASE_URL.replace('https://', 'postgresql://postgres:')\n",
    "        db_url = f\"{db_url.split('.')[0]}.{db_url.split('.')[1]}.supabase.co:5432/postgres\"\n",
    "        engine = create_engine(db_url + \"?sslmode=require&options=-c%20search_path%3Dpublic\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Database connection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test connections\n",
    "engine = get_db_connection()\n",
    "if engine:\n",
    "    print(\"‚úÖ Database connection established\")\n",
    "else:\n",
    "    print(\"‚ùå Database connection failed\")\n",
    "\n",
    "# Test orchestrator API\n",
    "try:\n",
    "    response = requests.get(f\"{ORCHESTRATOR_API}/health\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ AI Orchestrator API connected\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è AI Orchestrator API returned status {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è AI Orchestrator API not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Real-time System Health Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_metrics():\n",
    "    \"\"\"Fetch current system metrics from the orchestrator\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{ORCHESTRATOR_API}/metrics\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error fetching metrics: HTTP {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching metrics: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_health_dashboard():\n",
    "    \"\"\"Display a comprehensive health dashboard\"\"\"\n",
    "    metrics = get_system_metrics()\n",
    "    \n",
    "    if not metrics:\n",
    "        print(\"‚ùå Could not fetch system metrics\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üïê Last Update: {metrics['timestamp']}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create dashboard layout\n",
    "    table_metrics = metrics.get('table_metrics', {})\n",
    "    \n",
    "    # Prepare data for visualization\n",
    "    tables = []\n",
    "    record_counts = []\n",
    "    query_times = []\n",
    "    validation_statuses = []\n",
    "    freshness_hours = []\n",
    "    \n",
    "    for table_name, data in table_metrics.items():\n",
    "        if 'error' not in data:\n",
    "            tables.append(table_name)\n",
    "            record_counts.append(data.get('record_count', 0))\n",
    "            query_times.append(data.get('query_time_ms', 0))\n",
    "            validation_statuses.append(data.get('validation_status', 'unknown'))\n",
    "            freshness_hours.append(data.get('data_freshness_hours', 0))\n",
    "    \n",
    "    if not tables:\n",
    "        print(\"‚ùå No valid table metrics available\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Record Counts by Table', 'Query Performance (ms)', \n",
    "                       'Data Freshness (hours)', 'Validation Status'),\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"pie\"}]]\n",
    "    )\n",
    "    \n",
    "    # Record counts\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=tables, y=record_counts, name=\"Record Count\",\n",
    "               marker_color='lightblue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Query performance\n",
    "    color_scale = ['green' if qt < 1000 else 'orange' if qt < 3000 else 'red' for qt in query_times]\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=tables, y=query_times, name=\"Query Time (ms)\",\n",
    "               marker_color=color_scale),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Data freshness\n",
    "    freshness_colors = ['green' if fh < 24 else 'orange' if fh < 72 else 'red' for fh in freshness_hours]\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=tables, y=freshness_hours, name=\"Data Age (hours)\",\n",
    "               marker_color=freshness_colors),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Validation status pie chart\n",
    "    status_counts = pd.Series(validation_statuses).value_counts()\n",
    "    status_colors = {'healthy': 'green', 'warning': 'orange', 'error': 'red', 'unknown': 'gray'}\n",
    "    pie_colors = [status_colors.get(status, 'gray') for status in status_counts.index]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=status_counts.index, values=status_counts.values,\n",
    "               marker_colors=pie_colors, name=\"Validation Status\"),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"ConcordBroker Data Flow Health Dashboard\",\n",
    "        title_x=0.5,\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    fig.update_xaxes(tickangle=45)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Print detailed status\n",
    "    print(\"\\nüìã Detailed Table Status:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for table_name, data in table_metrics.items():\n",
    "        if 'error' in data:\n",
    "            print(f\"‚ùå {table_name:20} ERROR: {data['error']}\")\n",
    "        else:\n",
    "            status_icon = {\n",
    "                'healthy': '‚úÖ',\n",
    "                'warning': '‚ö†Ô∏è',\n",
    "                'error': '‚ùå',\n",
    "                'unknown': '‚ùì'\n",
    "            }.get(data.get('validation_status'), '‚ùì')\n",
    "            \n",
    "            print(f\"{status_icon} {table_name:20} \"\n",
    "                  f\"Records: {data.get('record_count', 0):>8,} | \"\n",
    "                  f\"Query: {data.get('query_time_ms', 0):>6.1f}ms | \"\n",
    "                  f\"Age: {data.get('data_freshness_hours', 0):>5.1f}h\")\n",
    "\n",
    "# Display the dashboard\n",
    "display_health_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_quality():\n",
    "    \"\"\"Comprehensive data quality analysis\"\"\"\n",
    "    if not engine:\n",
    "        print(\"‚ùå No database connection available\")\n",
    "        return\n",
    "    \n",
    "    print(\"üîç Analyzing Data Quality...\")\n",
    "    \n",
    "    # Critical tables to analyze\n",
    "    critical_tables = {\n",
    "        'florida_parcels': 'Main property data',\n",
    "        'property_sales_history': 'Sales transaction data',\n",
    "        'tax_certificates': 'Tax lien certificates',\n",
    "        'florida_entities': 'Business entities',\n",
    "        'sunbiz_corporate': 'Corporate registrations'\n",
    "    }\n",
    "    \n",
    "    quality_results = []\n",
    "    \n",
    "    for table_name, description in critical_tables.items():\n",
    "        try:\n",
    "            print(f\"   Analyzing {table_name}...\")\n",
    "            \n",
    "            # Basic statistics\n",
    "            basic_query = f\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total_records,\n",
    "                COUNT(DISTINCT parcel_id) as unique_parcels,\n",
    "                COUNT(CASE WHEN parcel_id IS NULL THEN 1 END) as null_parcel_ids,\n",
    "                ROUND(COUNT(CASE WHEN parcel_id IS NULL THEN 1 END) * 100.0 / COUNT(*), 2) as null_percentage\n",
    "            FROM {table_name}\n",
    "            \"\"\"\n",
    "            \n",
    "            df = pd.read_sql(basic_query, engine)\n",
    "            \n",
    "            if not df.empty:\n",
    "                result = df.iloc[0]\n",
    "                quality_results.append({\n",
    "                    'table': table_name,\n",
    "                    'description': description,\n",
    "                    'total_records': result['total_records'],\n",
    "                    'unique_parcels': result['unique_parcels'],\n",
    "                    'null_parcel_ids': result['null_parcel_ids'],\n",
    "                    'null_percentage': result['null_percentage'],\n",
    "                    'quality_score': max(0, 100 - result['null_percentage'])\n",
    "                })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error analyzing {table_name}: {e}\")\n",
    "            quality_results.append({\n",
    "                'table': table_name,\n",
    "                'description': description,\n",
    "                'total_records': 0,\n",
    "                'unique_parcels': 0,\n",
    "                'null_parcel_ids': 0,\n",
    "                'null_percentage': 100,\n",
    "                'quality_score': 0,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Create quality summary DataFrame\n",
    "    quality_df = pd.DataFrame(quality_results)\n",
    "    \n",
    "    # Visualize quality scores\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Quality scores bar chart\n",
    "    colors = ['green' if score >= 90 else 'orange' if score >= 70 else 'red' \n",
    "              for score in quality_df['quality_score']]\n",
    "    \n",
    "    bars1 = ax1.bar(quality_df['table'], quality_df['quality_score'], color=colors)\n",
    "    ax1.set_title('Data Quality Scores by Table', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Quality Score (%)')\n",
    "    ax1.set_ylim(0, 100)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Record counts\n",
    "    bars2 = ax2.bar(quality_df['table'], quality_df['total_records'], color='lightblue')\n",
    "    ax2.set_title('Total Records by Table', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Number of Records')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Format y-axis for better readability\n",
    "    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1000:.0f}K' if x >= 1000 else f'{x:.0f}'))\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:,.0f}', ha='center', va='bottom', rotation=90)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\nüìä Data Quality Analysis Results:\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    for _, row in quality_df.iterrows():\n",
    "        if 'error' in row and pd.notna(row['error']):\n",
    "            print(f\"‚ùå {row['table']:25} ERROR: {row['error']}\")\n",
    "        else:\n",
    "            quality_icon = '‚úÖ' if row['quality_score'] >= 90 else '‚ö†Ô∏è' if row['quality_score'] >= 70 else '‚ùå'\n",
    "            print(f\"{quality_icon} {row['table']:25} \"\n",
    "                  f\"Score: {row['quality_score']:>5.1f}% | \"\n",
    "                  f\"Records: {row['total_records']:>8,} | \"\n",
    "                  f\"Unique Parcels: {row['unique_parcels']:>8,} | \"\n",
    "                  f\"Null %: {row['null_percentage']:>5.1f}%\")\n",
    "    \n",
    "    # Overall system score\n",
    "    overall_score = quality_df[quality_df['quality_score'] > 0]['quality_score'].mean()\n",
    "    print(f\"\\nüéØ Overall System Quality Score: {overall_score:.1f}%\")\n",
    "    \n",
    "    if overall_score >= 90:\n",
    "        print(\"‚úÖ Excellent data quality!\")\n",
    "    elif overall_score >= 70:\n",
    "        print(\"‚ö†Ô∏è Good data quality with room for improvement\")\n",
    "    else:\n",
    "        print(\"‚ùå Data quality needs attention\")\n",
    "    \n",
    "    return quality_df\n",
    "\n",
    "# Run the analysis\n",
    "quality_results = analyze_data_quality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_system_performance():\n",
    "    \"\"\"Monitor and display system performance metrics\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{ORCHESTRATOR_API}/performance\", timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Error fetching performance data: HTTP {response.status_code}\")\n",
    "            return None\n",
    "        \n",
    "        perf_data = response.json()\n",
    "        \n",
    "        print(f\"‚ö° Performance Monitoring Report - {perf_data['timestamp']}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # System metrics\n",
    "        if 'system' in perf_data:\n",
    "            sys_data = perf_data['system']\n",
    "            \n",
    "            # Create performance visualization\n",
    "            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            \n",
    "            # CPU Usage gauge\n",
    "            cpu_usage = sys_data.get('cpu_usage', 0)\n",
    "            cpu_color = 'green' if cpu_usage < 70 else 'orange' if cpu_usage < 85 else 'red'\n",
    "            \n",
    "            ax1.pie([cpu_usage, 100-cpu_usage], labels=[f'Used: {cpu_usage:.1f}%', 'Free'], \n",
    "                   colors=[cpu_color, 'lightgray'], startangle=90, counterclock=False)\n",
    "            ax1.set_title('CPU Usage', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # Memory Usage gauge\n",
    "            mem_usage = sys_data.get('memory_usage', 0)\n",
    "            mem_color = 'green' if mem_usage < 70 else 'orange' if mem_usage < 85 else 'red'\n",
    "            \n",
    "            ax2.pie([mem_usage, 100-mem_usage], labels=[f'Used: {mem_usage:.1f}%', 'Free'],\n",
    "                   colors=[mem_color, 'lightgray'], startangle=90, counterclock=False)\n",
    "            ax2.set_title('Memory Usage', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # Disk Usage gauge\n",
    "            disk_usage = sys_data.get('disk_usage', 0)\n",
    "            disk_color = 'green' if disk_usage < 80 else 'orange' if disk_usage < 90 else 'red'\n",
    "            \n",
    "            ax3.pie([disk_usage, 100-disk_usage], labels=[f'Used: {disk_usage:.1f}%', 'Free'],\n",
    "                   colors=[disk_color, 'lightgray'], startangle=90, counterclock=False)\n",
    "            ax3.set_title('Disk Usage', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # Database connections\n",
    "            if 'database' in perf_data and 'active_connections' in perf_data['database']:\n",
    "                db_data = perf_data['database']\n",
    "                active_conn = db_data.get('active_connections', 0)\n",
    "                avg_query_time = db_data.get('avg_query_time_ms', 0)\n",
    "                \n",
    "                # Simple bar chart for database metrics\n",
    "                metrics = ['Active\\nConnections', 'Avg Query\\nTime (ms)']\n",
    "                values = [active_conn, avg_query_time]\n",
    "                colors_db = ['blue', 'green' if avg_query_time < 1000 else 'orange' if avg_query_time < 3000 else 'red']\n",
    "                \n",
    "                bars = ax4.bar(metrics, values, color=colors_db)\n",
    "                ax4.set_title('Database Performance', fontsize=14, fontweight='bold')\n",
    "                \n",
    "                # Add value labels\n",
    "                for bar, value in zip(bars, values):\n",
    "                    ax4.text(bar.get_x() + bar.get_width()/2., bar.get_height() + bar.get_height()*0.01,\n",
    "                            f'{value:.1f}', ha='center', va='bottom')\n",
    "            else:\n",
    "                ax4.text(0.5, 0.5, 'Database metrics\\nnot available', \n",
    "                        ha='center', va='center', transform=ax4.transAxes, fontsize=12)\n",
    "                ax4.set_title('Database Performance', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print detailed metrics\n",
    "            print(\"\\nüíª System Resource Usage:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"CPU Usage:           {cpu_usage:>6.1f}%\")\n",
    "            print(f\"Memory Usage:        {mem_usage:>6.1f}%\")\n",
    "            print(f\"Memory Available:    {sys_data.get('memory_available_gb', 0):>6.1f} GB\")\n",
    "            print(f\"Disk Usage:          {disk_usage:>6.1f}%\")\n",
    "            print(f\"Disk Free:           {sys_data.get('disk_free_gb', 0):>6.1f} GB\")\n",
    "            \n",
    "            if 'database' in perf_data:\n",
    "                db_data = perf_data['database']\n",
    "                print(f\"\\nüóÑÔ∏è Database Performance:\")\n",
    "                print(\"-\" * 40)\n",
    "                print(f\"Active Connections:  {db_data.get('active_connections', 0):>6}\")\n",
    "                print(f\"Avg Query Time:      {db_data.get('avg_query_time_ms', 0):>6.1f} ms\")\n",
    "            \n",
    "            # Check for alerts\n",
    "            if 'alerts' in perf_data and perf_data['alerts']:\n",
    "                print(f\"\\nüö® Performance Alerts:\")\n",
    "                print(\"-\" * 40)\n",
    "                for alert in perf_data['alerts']:\n",
    "                    print(f\"‚ö†Ô∏è {alert}\")\n",
    "            else:\n",
    "                print(f\"\\n‚úÖ No performance alerts\")\n",
    "        \n",
    "        return perf_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error monitoring performance: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run performance monitoring\n",
    "performance_data = monitor_system_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validation Status and Self-Healing Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_validation():\n",
    "    \"\"\"Run comprehensive validation and display results\"\"\"\n",
    "    try:\n",
    "        print(\"üîç Running comprehensive data validation...\")\n",
    "        \n",
    "        response = requests.post(f\"{ORCHESTRATOR_API}/validate/all\", timeout=30)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Validation request failed: HTTP {response.status_code}\")\n",
    "            return None\n",
    "        \n",
    "        validation_data = response.json()\n",
    "        results = validation_data.get('validation_results', [])\n",
    "        \n",
    "        if not results:\n",
    "            print(\"‚ö†Ô∏è No validation results received\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"‚úÖ Validation completed at {validation_data['timestamp']}\")\n",
    "        \n",
    "        # Analyze results\n",
    "        table_validations = [r for r in results if r['validation_type'] == 'table_integrity']\n",
    "        relationship_validations = [r for r in results if r['validation_type'] == 'referential_integrity']\n",
    "        \n",
    "        # Create summary visualization\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Table validation results\n",
    "        if table_validations:\n",
    "            table_names = [r['table_name'] for r in table_validations]\n",
    "            table_passed = [r['passed'] for r in table_validations]\n",
    "            \n",
    "            colors = ['green' if passed else 'red' for passed in table_passed]\n",
    "            bars1 = ax1.bar(table_names, [1 if p else 0 for p in table_passed], color=colors)\n",
    "            ax1.set_title('Table Validation Results', fontsize=14, fontweight='bold')\n",
    "            ax1.set_ylabel('Status (1=Pass, 0=Fail)')\n",
    "            ax1.set_ylim(0, 1.2)\n",
    "            ax1.tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Add status labels\n",
    "            for bar, passed in zip(bars1, table_passed):\n",
    "                status = '‚úÖ PASS' if passed else '‚ùå FAIL'\n",
    "                ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.05,\n",
    "                        status, ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # Relationship validation results\n",
    "        if relationship_validations:\n",
    "            rel_names = [f\"{r['table_name']}\\n{r['validation_type']}\" for r in relationship_validations]\n",
    "            rel_passed = [r['passed'] for r in relationship_validations]\n",
    "            \n",
    "            colors = ['green' if passed else 'red' for passed in rel_passed]\n",
    "            bars2 = ax2.bar(rel_names, [1 if p else 0 for p in rel_passed], color=colors)\n",
    "            ax2.set_title('Relationship Validation Results', fontsize=14, fontweight='bold')\n",
    "            ax2.set_ylabel('Status (1=Pass, 0=Fail)')\n",
    "            ax2.set_ylim(0, 1.2)\n",
    "            ax2.tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Add status labels\n",
    "            for bar, passed in zip(bars2, rel_passed):\n",
    "                status = '‚úÖ PASS' if passed else '‚ùå FAIL'\n",
    "                ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.05,\n",
    "                        status, ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed results\n",
    "        print(\"\\nüìã Detailed Validation Results:\")\n",
    "        print(\"=\" * 100)\n",
    "        \n",
    "        for result in results:\n",
    "            status_icon = '‚úÖ' if result['passed'] else '‚ùå'\n",
    "            print(f\"{status_icon} {result['table_name']:25} \"\n",
    "                  f\"{result['validation_type']:20} - {result['message']}\")\n",
    "            \n",
    "            # Show additional details for failed validations\n",
    "            if not result['passed'] and result.get('details'):\n",
    "                details = result['details']\n",
    "                if 'total_records' in details:\n",
    "                    print(f\"    üìä Records: {details['total_records']:,}\")\n",
    "                if 'validation_checks' in details:\n",
    "                    for check in details['validation_checks']:\n",
    "                        check_icon = '‚úÖ' if check['passed'] else '‚ùå'\n",
    "                        print(f\"    {check_icon} {check['column']}: {check['null_percentage']:.1f}% null\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        total_validations = len(results)\n",
    "        passed_validations = sum(1 for r in results if r['passed'])\n",
    "        success_rate = (passed_validations / total_validations * 100) if total_validations > 0 else 0\n",
    "        \n",
    "        print(f\"\\nüìà Validation Summary:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Total Validations:   {total_validations:>3}\")\n",
    "        print(f\"Passed:              {passed_validations:>3}\")\n",
    "        print(f\"Failed:              {total_validations - passed_validations:>3}\")\n",
    "        print(f\"Success Rate:        {success_rate:>6.1f}%\")\n",
    "        \n",
    "        if success_rate >= 95:\n",
    "            print(\"\\n‚úÖ Excellent! System validation passed with flying colors!\")\n",
    "        elif success_rate >= 80:\n",
    "            print(\"\\n‚ö†Ô∏è Good validation results with minor issues to address\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå Validation identified significant issues requiring attention\")\n",
    "        \n",
    "        return validation_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error running validation: {e}\")\n",
    "        return None\n",
    "\n",
    "def trigger_self_healing():\n",
    "    \"\"\"Trigger the self-healing process and monitor results\"\"\"\n",
    "    try:\n",
    "        print(\"üîß Triggering self-healing process...\")\n",
    "        \n",
    "        response = requests.post(f\"{ORCHESTRATOR_API}/heal\", timeout=60)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå Self-healing request failed: HTTP {response.status_code}\")\n",
    "            return None\n",
    "        \n",
    "        healing_data = response.json()\n",
    "        healing_actions = healing_data.get('healing_actions', [])\n",
    "        \n",
    "        print(f\"‚úÖ Self-healing completed at {healing_data['timestamp']}\")\n",
    "        \n",
    "        if healing_actions:\n",
    "            print(f\"\\nüîß Healing Actions Performed ({len(healing_actions)}):\")\n",
    "            print(\"-\" * 60)\n",
    "            for i, action in enumerate(healing_actions, 1):\n",
    "                print(f\"   {i}. {action}\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ No healing actions were needed - system is healthy!\")\n",
    "        \n",
    "        return healing_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error triggering self-healing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run validation and healing\n",
    "validation_results = run_full_validation()\n",
    "\n",
    "if validation_results:\n",
    "    # Check if healing is needed\n",
    "    failed_validations = [r for r in validation_results.get('validation_results', []) if not r['passed']]\n",
    "    \n",
    "    if failed_validations:\n",
    "        print(f\"\\nüîß Found {len(failed_validations)} failed validations. Triggering self-healing...\")\n",
    "        healing_results = trigger_self_healing()\n",
    "    else:\n",
    "        print(\"\\n‚úÖ All validations passed - no healing needed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real-time Monitoring Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_continuous_monitoring():\n",
    "    \"\"\"Start the continuous monitoring service\"\"\"\n",
    "    try:\n",
    "        response = requests.post(f\"{ORCHESTRATOR_API}/start-monitoring\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"‚úÖ {result['message']}\")\n",
    "            print(f\"üìä Monitoring interval: {result.get('interval_seconds', 'unknown')} seconds\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to start monitoring: HTTP {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error starting monitoring: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_live_dashboard():\n",
    "    \"\"\"Create a live monitoring dashboard\"\"\"\n",
    "    from IPython.display import clear_output\n",
    "    import time\n",
    "    \n",
    "    print(\"üî¥ Starting Live Data Flow Monitoring Dashboard\")\n",
    "    print(\"Press Ctrl+C to stop monitoring\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Start monitoring service\n",
    "        start_continuous_monitoring()\n",
    "        \n",
    "        # Live monitoring loop\n",
    "        iteration = 0\n",
    "        while iteration < 5:  # Limit to 5 iterations for notebook demo\n",
    "            iteration += 1\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print(f\"üî¥ LIVE MONITORING - Iteration {iteration}/5\")\n",
    "            print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            # Get current health status\n",
    "            try:\n",
    "                health_response = requests.get(f\"{ORCHESTRATOR_API}/health\", timeout=5)\n",
    "                if health_response.status_code == 200:\n",
    "                    health_data = health_response.json()\n",
    "                    print(f\"üü¢ Orchestrator Status: {health_data['status']}\")\n",
    "                    print(f\"üìä Monitoring Active: {health_data['monitoring_active']}\")\n",
    "                    if health_data['last_check']:\n",
    "                        print(f\"üïê Last Check: {health_data['last_check']}\")\n",
    "                else:\n",
    "                    print(f\"üî¥ Orchestrator Status: ERROR (HTTP {health_response.status_code})\")\n",
    "            except:\n",
    "                print(\"üî¥ Orchestrator Status: UNAVAILABLE\")\n",
    "            \n",
    "            print(\"\\n\" + \"-\" * 40)\n",
    "            \n",
    "            # Get quick metrics\n",
    "            try:\n",
    "                metrics_response = requests.get(f\"{ORCHESTRATOR_API}/metrics\", timeout=10)\n",
    "                if metrics_response.status_code == 200:\n",
    "                    metrics = metrics_response.json()\n",
    "                    table_metrics = metrics.get('table_metrics', {})\n",
    "                    \n",
    "                    print(\"üìä Table Status Summary:\")\n",
    "                    for table_name, data in table_metrics.items():\n",
    "                        if 'error' not in data:\n",
    "                            status_icon = {\n",
    "                                'healthy': 'üü¢',\n",
    "                                'warning': 'üü°',\n",
    "                                'error': 'üî¥',\n",
    "                                'unknown': '‚ö™'\n",
    "                            }.get(data.get('validation_status'), '‚ö™')\n",
    "                            \n",
    "                            record_count = data.get('record_count', 0)\n",
    "                            query_time = data.get('query_time_ms', 0)\n",
    "                            \n",
    "                            print(f\"   {status_icon} {table_name[:20]:20} \"\n",
    "                                  f\"Records: {record_count:>8,} | \"\n",
    "                                  f\"Query: {query_time:>6.1f}ms\")\n",
    "                        else:\n",
    "                            print(f\"   üî¥ {table_name[:20]:20} ERROR: {data['error'][:30]}...\")\n",
    "                else:\n",
    "                    print(\"üî¥ Could not fetch table metrics\")\n",
    "            except:\n",
    "                print(\"üî¥ Metrics service unavailable\")\n",
    "            \n",
    "            print(\"\\n\" + \"-\" * 40)\n",
    "            \n",
    "            # Get performance snapshot\n",
    "            try:\n",
    "                perf_response = requests.get(f\"{ORCHESTRATOR_API}/performance\", timeout=5)\n",
    "                if perf_response.status_code == 200:\n",
    "                    perf_data = perf_response.json()\n",
    "                    if 'system' in perf_data:\n",
    "                        sys_data = perf_data['system']\n",
    "                        print(\"‚ö° System Performance:\")\n",
    "                        print(f\"   CPU: {sys_data.get('cpu_usage', 0):>5.1f}% | \"\n",
    "                              f\"Memory: {sys_data.get('memory_usage', 0):>5.1f}% | \"\n",
    "                              f\"Disk: {sys_data.get('disk_usage', 0):>5.1f}%\")\n",
    "                        \n",
    "                        if 'alerts' in perf_data and perf_data['alerts']:\n",
    "                            print(f\"   üö® Alerts: {len(perf_data['alerts'])}\")\n",
    "                            for alert in perf_data['alerts'][:2]:  # Show max 2 alerts\n",
    "                                print(f\"      ‚Ä¢ {alert}\")\n",
    "                        else:\n",
    "                            print(\"   ‚úÖ No performance alerts\")\n",
    "                else:\n",
    "                    print(\"üî¥ Performance data unavailable\")\n",
    "            except:\n",
    "                print(\"üî¥ Performance monitoring unavailable\")\n",
    "            \n",
    "            print(f\"\\n‚è∞ Next update in 30 seconds... (Iteration {iteration}/5)\")\n",
    "            \n",
    "            if iteration < 5:\n",
    "                time.sleep(30)  # Wait 30 seconds between updates\n",
    "        \n",
    "        print(\"\\n‚úÖ Live monitoring demo completed (5 iterations)\")\n",
    "        print(\"To continue monitoring, run the cell again or check the orchestrator directly at http://localhost:8001\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Monitoring stopped by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error in live monitoring: {e}\")\n",
    "\n",
    "# Create live dashboard\n",
    "create_live_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Flow Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comprehensive_report():\n",
    "    \"\"\"Generate a comprehensive data flow report\"\"\"\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    report_file = f\"../logs/data_flow_report_{timestamp}.md\"\n",
    "    \n",
    "    print(f\"üìù Generating comprehensive data flow report...\")\n",
    "    print(f\"üìÑ Report will be saved to: {report_file}\")\n",
    "    \n",
    "    try:\n",
    "        # Collect all data\n",
    "        metrics = get_system_metrics()\n",
    "        performance = monitor_system_performance()\n",
    "        validation = run_full_validation()\n",
    "        \n",
    "        # Create report content\n",
    "        report_content = f\"\"\"\n",
    "# ConcordBroker Data Flow Monitoring Report\n",
    "\n",
    "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This report provides a comprehensive overview of the ConcordBroker data flow monitoring system status, including:\n",
    "- System health and performance metrics\n",
    "- Data quality validation results\n",
    "- Self-healing actions and recommendations\n",
    "\n",
    "## System Health Overview\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if metrics and 'table_metrics' in metrics:\n",
    "            table_metrics = metrics['table_metrics']\n",
    "            healthy_tables = sum(1 for data in table_metrics.values() \n",
    "                                if 'error' not in data and data.get('validation_status') == 'healthy')\n",
    "            total_tables = len(table_metrics)\n",
    "            total_records = sum(data.get('record_count', 0) for data in table_metrics.values() \n",
    "                               if 'error' not in data)\n",
    "            \n",
    "            report_content += f\"\"\"\n",
    "### Table Health Status\n",
    "- **Total Tables Monitored:** {total_tables}\n",
    "- **Healthy Tables:** {healthy_tables}\n",
    "- **Health Rate:** {(healthy_tables/total_tables*100):.1f}%\n",
    "- **Total Records:** {total_records:,}\n",
    "\n",
    "### Table Details\n",
    "\n",
    "| Table Name | Status | Records | Query Time (ms) | Data Age (hours) |\n",
    "|------------|--------|---------|-----------------|------------------|\n",
    "\"\"\"\n",
    "            \n",
    "            for table_name, data in table_metrics.items():\n",
    "                if 'error' not in data:\n",
    "                    status = data.get('validation_status', 'unknown').upper()\n",
    "                    records = f\"{data.get('record_count', 0):,}\"\n",
    "                    query_time = f\"{data.get('query_time_ms', 0):.1f}\"\n",
    "                    data_age = f\"{data.get('data_freshness_hours', 0):.1f}\"\n",
    "                    \n",
    "                    report_content += f\"| {table_name} | {status} | {records} | {query_time} | {data_age} |\\n\"\n",
    "                else:\n",
    "                    report_content += f\"| {table_name} | ERROR | - | - | - |\\n\"\n",
    "        \n",
    "        # Performance section\n",
    "        if performance and 'system' in performance:\n",
    "            sys_data = performance['system']\n",
    "            report_content += f\"\"\"\n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "### System Resources\n",
    "- **CPU Usage:** {sys_data.get('cpu_usage', 0):.1f}%\n",
    "- **Memory Usage:** {sys_data.get('memory_usage', 0):.1f}%\n",
    "- **Memory Available:** {sys_data.get('memory_available_gb', 0):.1f} GB\n",
    "- **Disk Usage:** {sys_data.get('disk_usage', 0):.1f}%\n",
    "- **Disk Free:** {sys_data.get('disk_free_gb', 0):.1f} GB\n",
    "\"\"\"\n",
    "            \n",
    "            if 'database' in performance:\n",
    "                db_data = performance['database']\n",
    "                report_content += f\"\"\"\n",
    "\n",
    "### Database Performance\n",
    "- **Active Connections:** {db_data.get('active_connections', 0)}\n",
    "- **Average Query Time:** {db_data.get('avg_query_time_ms', 0):.1f} ms\n",
    "\"\"\"\n",
    "            \n",
    "            if 'alerts' in performance and performance['alerts']:\n",
    "                report_content += f\"\"\"\n",
    "\n",
    "### Performance Alerts\n",
    "\"\"\"\n",
    "                for alert in performance['alerts']:\n",
    "                    report_content += f\"- ‚ö†Ô∏è {alert}\\n\"\n",
    "        \n",
    "        # Validation section\n",
    "        if validation and 'validation_results' in validation:\n",
    "            results = validation['validation_results']\n",
    "            passed = sum(1 for r in results if r['passed'])\n",
    "            total = len(results)\n",
    "            \n",
    "            report_content += f\"\"\"\n",
    "\n",
    "## Data Validation Results\n",
    "\n",
    "### Validation Summary\n",
    "- **Total Validations:** {total}\n",
    "- **Passed:** {passed}\n",
    "- **Failed:** {total - passed}\n",
    "- **Success Rate:** {(passed/total*100):.1f}%\n",
    "\n",
    "### Detailed Validation Results\n",
    "\n",
    "| Table | Validation Type | Status | Message |\n",
    "|-------|----------------|--------|----------|\n",
    "\"\"\"\n",
    "            \n",
    "            for result in results:\n",
    "                status = \"‚úÖ PASS\" if result['passed'] else \"‚ùå FAIL\"\n",
    "                table = result['table_name']\n",
    "                val_type = result['validation_type']\n",
    "                message = result['message'][:50] + \"...\" if len(result['message']) > 50 else result['message']\n",
    "                \n",
    "                report_content += f\"| {table} | {val_type} | {status} | {message} |\\n\"\n",
    "        \n",
    "        # Recommendations\n",
    "        report_content += f\"\"\"\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "### Immediate Actions\n",
    "\"\"\"\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # Check for failed validations\n",
    "        if validation and 'validation_results' in validation:\n",
    "            failed = [r for r in validation['validation_results'] if not r['passed']]\n",
    "            if failed:\n",
    "                recommendations.append(f\"üîß Address {len(failed)} failed validation(s)\")\n",
    "            else:\n",
    "                recommendations.append(\"‚úÖ All validations passing - excellent data quality\")\n",
    "        \n",
    "        # Check performance alerts\n",
    "        if performance and performance.get('alerts'):\n",
    "            recommendations.append(f\"‚ö° Review {len(performance['alerts'])} performance alert(s)\")\n",
    "        \n",
    "        # Check system resources\n",
    "        if performance and 'system' in performance:\n",
    "            sys_data = performance['system']\n",
    "            if sys_data.get('cpu_usage', 0) > 80:\n",
    "                recommendations.append(\"üíª High CPU usage detected - consider scaling\")\n",
    "            if sys_data.get('memory_usage', 0) > 85:\n",
    "                recommendations.append(\"üß† High memory usage detected - monitor for memory leaks\")\n",
    "            if sys_data.get('disk_usage', 0) > 85:\n",
    "                recommendations.append(\"üíæ High disk usage detected - cleanup may be needed\")\n",
    "        \n",
    "        if not recommendations:\n",
    "            recommendations.append(\"‚úÖ System is operating optimally - no immediate actions required\")\n",
    "        \n",
    "        for rec in recommendations:\n",
    "            report_content += f\"- {rec}\\n\"\n",
    "        \n",
    "        report_content += f\"\"\"\n",
    "\n",
    "### Ongoing Monitoring\n",
    "- Continue automated monitoring at 5-minute intervals\n",
    "- Review daily reports for trends and patterns\n",
    "- Ensure self-healing mechanisms are functioning\n",
    "- Monitor data freshness and update frequencies\n",
    "\n",
    "---\n",
    "\n",
    "**Report Generated by ConcordBroker AI Data Flow Orchestrator**  \n",
    "**Timestamp:** {datetime.now().isoformat()}\n",
    "\"\"\"\n",
    "        \n",
    "        # Ensure logs directory exists\n",
    "        os.makedirs('../logs', exist_ok=True)\n",
    "        \n",
    "        # Write report to file\n",
    "        with open(report_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_content)\n",
    "        \n",
    "        print(f\"‚úÖ Report successfully generated: {report_file}\")\n",
    "        \n",
    "        # Display summary\n",
    "        print(\"\\nüìä Report Summary:\")\n",
    "        print(\"-\" * 40)\n",
    "        if metrics and 'table_metrics' in metrics:\n",
    "            total_tables = len(metrics['table_metrics'])\n",
    "            healthy_tables = sum(1 for data in metrics['table_metrics'].values() \n",
    "                                if 'error' not in data and data.get('validation_status') == 'healthy')\n",
    "            print(f\"Tables Monitored: {total_tables}\")\n",
    "            print(f\"Healthy Tables:   {healthy_tables}\")\n",
    "            print(f\"Health Rate:      {(healthy_tables/total_tables*100):.1f}%\")\n",
    "        \n",
    "        if validation and 'validation_results' in validation:\n",
    "            results = validation['validation_results']\n",
    "            passed = sum(1 for r in results if r['passed'])\n",
    "            print(f\"Validations:      {passed}/{len(results)} passed ({(passed/len(results)*100):.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nüìÑ Full report saved to: {os.path.abspath(report_file)}\")\n",
    "        \n",
    "        return report_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating report: {e}\")\n",
    "        return None\n",
    "\n",
    "# Generate the report\n",
    "report_path = generate_comprehensive_report()\n",
    "\n",
    "if report_path:\n",
    "    print(f\"\\nüéâ Data Flow Monitoring Report Complete!\")\n",
    "    print(f\"üìñ You can view the full report at: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides comprehensive monitoring of the ConcordBroker data flow system including:\n",
    "\n",
    "1. **Real-time Health Dashboard** - Live monitoring of all critical tables\n",
    "2. **Data Quality Analysis** - Automated validation and quality scoring\n",
    "3. **Performance Monitoring** - System resource and database performance tracking\n",
    "4. **Validation & Self-Healing** - Automated issue detection and resolution\n",
    "5. **Live Monitoring** - Continuous real-time status updates\n",
    "6. **Report Generation** - Comprehensive status reports\n",
    "\n",
    "The AI-powered orchestrator ensures:\n",
    "- ‚úÖ Property tabs always get correct data\n",
    "- ‚úÖ MiniPropertyCards show real-time accurate information\n",
    "- ‚úÖ Filters work with proper database queries\n",
    "- ‚úÖ Sales history from property_sales_history table is accessible\n",
    "- ‚úÖ Entity linking from florida_entities and sunbiz_corporate works\n",
    "- ‚úÖ Tax certificates from tax_certificates table are properly linked\n",
    "\n",
    "**Next Steps:**\n",
    "1. Keep the orchestrator running at http://localhost:8001\n",
    "2. Monitor the logs in ../logs/ directory\n",
    "3. Review daily reports for trends and issues\n",
    "4. Ensure continuous monitoring is active\n",
    "\n",
    "**ü§ñ AI Agent Status: ACTIVE & MONITORING**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}